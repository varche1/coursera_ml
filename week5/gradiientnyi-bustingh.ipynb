{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "data_frame = pandas.read_csv(filepath_or_buffer='gbm-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data_frame.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data_frame[\"Activity\"].values\n",
    "X = data_frame.drop(\"Activity\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0190            1.29m\n",
      "         2           0.9192            1.26m\n",
      "         3           0.8272            1.14m\n",
      "         4           0.7834            1.06m\n",
      "         5           0.7109            1.04m\n",
      "         6           0.6368            1.06m\n",
      "         7           0.5797            1.05m\n",
      "         8           0.5610            1.01m\n",
      "         9           0.5185           59.94s\n",
      "        10           0.4984           58.53s\n",
      "        20           0.1999           56.51s\n",
      "        30           0.1313           52.96s\n",
      "        40           0.0790           49.83s\n",
      "        50           0.0511           46.78s\n",
      "        60           0.0352           44.31s\n",
      "        70           0.0245           41.59s\n",
      "        80           0.0162           39.22s\n",
      "        90           0.0114           36.86s\n",
      "       100           0.0077           34.61s\n",
      "       200           0.0004           10.71s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1255            1.26m\n",
      "         2           1.0035            1.24m\n",
      "         3           0.9386            1.22m\n",
      "         4           0.8844            1.15m\n",
      "         5           0.8381            1.12m\n",
      "         6           0.7995            1.09m\n",
      "         7           0.7559            1.06m\n",
      "         8           0.7205            1.04m\n",
      "         9           0.6958            1.02m\n",
      "        10           0.6725            1.01m\n",
      "        20           0.4672           55.04s\n",
      "        30           0.3179           52.77s\n",
      "        40           0.2274           50.44s\n",
      "        50           0.1774           47.44s\n",
      "        60           0.1394           44.84s\n",
      "        70           0.1050           42.54s\n",
      "        80           0.0805           40.07s\n",
      "        90           0.0650           37.48s\n",
      "       100           0.0511           35.27s\n",
      "       200           0.0058           11.65s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2095            1.26m\n",
      "         2           1.1006            1.27m\n",
      "         3           1.0240            1.26m\n",
      "         4           0.9729            1.25m\n",
      "         5           0.9387            1.17m\n",
      "         6           0.8948            1.18m\n",
      "         7           0.8621            1.15m\n",
      "         8           0.8360            1.12m\n",
      "         9           0.8171            1.08m\n",
      "        10           0.7883            1.07m\n",
      "        20           0.6164           57.50s\n",
      "        30           0.4933           53.58s\n",
      "        40           0.4248           49.62s\n",
      "        50           0.3345           47.33s\n",
      "        60           0.2760           44.65s\n",
      "        70           0.2263           42.18s\n",
      "        80           0.1971           39.44s\n",
      "        90           0.1693           36.96s\n",
      "       100           0.1388           34.99s\n",
      "       200           0.0294           11.61s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2613            1.21m\n",
      "         2           1.1715            1.23m\n",
      "         3           1.1009            1.21m\n",
      "         4           1.0529            1.20m\n",
      "         5           1.0130            1.21m\n",
      "         6           0.9740            1.20m\n",
      "         7           0.9475            1.15m\n",
      "         8           0.9197            1.15m\n",
      "         9           0.8979            1.12m\n",
      "        10           0.8730            1.12m\n",
      "        20           0.7207           59.49s\n",
      "        30           0.6055           54.89s\n",
      "        40           0.5244           51.11s\n",
      "        50           0.4501           48.46s\n",
      "        60           0.3908           46.06s\n",
      "        70           0.3372           43.91s\n",
      "        80           0.3009           41.51s\n",
      "        90           0.2603           39.22s\n",
      "       100           0.2327           36.62s\n",
      "       200           0.0835           11.95s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3199            1.21m\n",
      "         2           1.2645            1.22m\n",
      "         3           1.2170            1.21m\n",
      "         4           1.1775            1.21m\n",
      "         5           1.1404            1.22m\n",
      "         6           1.1106            1.22m\n",
      "         7           1.0844            1.21m\n",
      "         8           1.0617            1.20m\n",
      "         9           1.0411            1.20m\n",
      "        10           1.0223            1.19m\n",
      "        20           0.8864            1.09m\n",
      "        30           0.7844           59.80s\n",
      "        40           0.7176           54.87s\n",
      "        50           0.6590           51.07s\n",
      "        60           0.6120           47.54s\n",
      "        70           0.5599           44.73s\n",
      "        80           0.5242           41.90s\n",
      "        90           0.4829           39.25s\n",
      "       100           0.4473           36.56s\n",
      "       200           0.2379           11.82s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "n_estimators = 250\n",
    "# n_estimators = 8\n",
    "\n",
    "\n",
    "def get_result_for_learning_rate(learning_rate):\n",
    "    clf = GradientBoostingClassifier(n_estimators=n_estimators, verbose=True, random_state=241, learning_rate=learning_rate)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    log_loss_train = []\n",
    "    for y_pred in clf.staged_decision_function(X_train):\n",
    "        log_loss_train.append(log_loss(y_train, 1.0/(1.0 + np.exp(-y_pred))))\n",
    "        \n",
    "    log_loss_test = []\n",
    "    for y_pred in clf.staged_decision_function(X_test):\n",
    "        log_loss_test.append(log_loss(y_test, 1.0/(1.0 + np.exp(-y_pred))))\n",
    "    \n",
    "    return log_loss_train, log_loss_test\n",
    "    \n",
    "scores = []\n",
    "for learning_rate in [1, 0.5, 0.3, 0.2, 0.1]:\n",
    "    log_loss_train, log_loss_test = get_result_for_learning_rate(learning_rate)\n",
    "    scores.append((learning_rate, log_loss_train, log_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for learning_rate_data in scores:\n",
    "#     fig = plt.figure()\n",
    "#     fig.canvas.set_window_title(learning_rate_data[0]) \n",
    "#     plt.plot(learning_rate_data[1], 'g', linewidth=2)\n",
    "#     plt.plot(learning_rate_data[2], 'r', linewidth=2)\n",
    "#     plt.legend([\"train\", \"test\"])\n",
    "#     plt.show()\n",
    "\n",
    "[1, 0.5, 0.3, 0.2, 0.1]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(scores[0][1], 'b', linewidth=1)\n",
    "plt.plot(scores[0][2], 'b--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[1][1], 'g', linewidth=1)\n",
    "plt.plot(scores[1][2], 'g--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[2][1], 'r', linewidth=1)\n",
    "plt.plot(scores[2][2], 'r--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[3][1], 'c', linewidth=1)\n",
    "plt.plot(scores[3][2], 'c--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[4][1], 'm', linewidth=1)\n",
    "plt.plot(scores[4][2], 'm--', linewidth=1)\n",
    "\n",
    "plt.legend([\"1-train\", \"1-test\", \n",
    "            \"0.5-train\", \"0.5-test\", \n",
    "            \"0.3-train\", \"0.3-test\", \n",
    "            \"0.2-train\", \"0.2-test\", \n",
    "            \"0.1-train\", \"0.1-test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "0.530439819735\n"
     ]
    }
   ],
   "source": [
    "print(scores[3][2].index(min(scores[3][2])))\n",
    "print(min(scores[3][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=37, n_jobs=1,\n",
       "            oob_score=False, random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_forest = RandomForestClassifier(n_estimators=37, random_state=241)\n",
    "clf_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54091190993698968"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predictions[:, 1]\n",
    "log_loss(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
